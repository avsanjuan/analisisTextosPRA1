{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.877 · Análisis de sentimientos y textos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencias de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicaciones</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PAC 1: Procesamiento y análisis de información textual\n",
    "\n",
    "En esta práctica revisaremos y aplicaremos los conocimientos aprendidos en el módulo 1. Concretamente trataremos 3 temas.\n",
    "\n",
    "<ul>\n",
    "<li>1. Obtención de datos a partir de información textual\n",
    "<li>2. Detección de temas\n",
    "<li>3. Clasificación de textos\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El propósito de la práctica es descubrir rasgos característicos de las noticias falsas sobre el Covid-19 usando las herramientas explicadas en el módulo 1. Además veremos si es posible clasificar automáticamente noticias falsas con métodos de machine learning. Utilizaremos el dataset <i>corona_fake.csv</i>. Este dataset contiene noticias en inglés sobre el covid-19 etiquetadas según si son noticias falsas (<i>fake</i>) o no. El dataset se organiza en cuatro columnas:\n",
    "\n",
    "<b>title</b>: títular de la noticia<br>\n",
    "<b>text</b>: cuerpo de la noticia<br>\n",
    "<b>source</b>: fuente de la noticia<br>\n",
    "<b>label</b>: etiqueta <i>Fake</i> si la noticia es falsa. Etiqueta <i>TRUE</i> si es verdadera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('all')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"corona_fake.csv\")\n",
    "#df= pd.read_csv(\"/content/drive/My Drive/vicente/Analisis de sentimientos y textos/PRA1/corona_fake.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Obtención de datos a partir de información textual (5 puntos)\n",
    "\n",
    "Primero, cargamos las librerías necesarias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos dos dataframes. El primero (df_fake) contendrá las noticias clasificadas como <i>Fake</i> y el segundo dataframe (df_true) contendrá las noticias clasificadas como <i>TRUE</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = df.loc[df['label'] == 'Fake']\n",
    "\n",
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = df.loc[df['label'] == 'TRUE']\n",
    "\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Encontrar colocaciones (2 puntos)\n",
    "\n",
    "Recordad que las colocaciones son términos multipalabra, es decir, secuencias de palabras que tienen un significado en conjunto significativamente diferente del significado derivado de los significados de las palabras individuales  (e.g. New York tiene un significado distinto del que se puede derivar de New y de York)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong>  Computa los mejores bigramas y trigramas de los titulares de las noticias falsas que no están en los titulares de las noticias verdaderas (1 punto)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar la lista de stopwords en inglés de la libreria NLTK.\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "#Añadir stopwords\n",
    "stopwords = stopwords + ['unknown', 've', 'hadn', 'll', 'didn', 'isn', 'doesn', 'hasn' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este apartado hay que cargar las siguientes librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.collocations import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del comando help(nltk.collocations.BigramAssocMeasures) explora la clase BigramAssocMeasures del módulo nltk.metrics.association y revisa las definiciones de las métricas de Likelihood Ratio (likelihood_ratio) y de Pointwise Mutual Information (pmi) en las secciones que se indican del capítulo 5 del libro Foundations of Statistical Natural Language Processing (Manning & Schutze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(nltk.collocations.BigramAssocMeasures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer paso: Computa los tokens de los titulares de las noticias falsas. Etiqueta estos tokens por su PoS. Ten en cuenta que hay noticias sin titular y que puede haber titulares con palabras que tengan caracteres especiales al principio. Si una noticia no tiene titular (NaN en la columna 'title') sustituimos NaN por 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sustituimos 'Nan' por 'empty'\n",
    "df_no_na = df.fillna('empty')\n",
    "\n",
    "#Creamos un dataframe que contiene las noticias falsas\n",
    "df_fake = df_no_na.loc[df['label'] == 'Fake']\n",
    "\n",
    "#Creamos un dataframe que contiene las noticias verdaderas\n",
    "df_true = df_no_na.loc[df['label'] == 'TRUE']\n",
    "\n",
    "#Quitamos los titulares vacíos \n",
    "\n",
    "titulares_fake_noempty = [fh for fh in df_fake['title'].to_list() if fh != 'empty']\n",
    "titulares_true_noempty = [th for th in df_true['title'].to_list() if th != 'empty']\n",
    "\n",
    "#Creamos un texto en minúscula con todos los titulares falsos\n",
    "\n",
    "titulares_fake = \" \".join(titulares_fake_noempty).lower()\n",
    "\n",
    "#Creamos un texto en minúscula con todos los titulares verdaderos\n",
    "\n",
    "titulares_true = \" \".join(titulares_true_noempty).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                   #\n",
    "#############################################\n",
    "from nltk import word_tokenize\n",
    "alpha_tokens = [w for w in word_tokenize(titulares_fake) if re.match(\"^[a-z]+.*\", w)]\n",
    "tagged_tokens = nltk.pos_tag(alpha_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo paso: Computa los 1000 mejores bigramas y los 1000 mejores trigramas a partir de los tokens etiquetados (e.g. [(Basic, JJ), ...]) de los titulares falsos. Utiliza las métricas PMI y la Likehood Ratio. Tienes que comentar las similitudes y diferencias que encuentras en los resultados según la métrica utilizada.\n",
    "\n",
    "<b>Atención</b>: De los 1000 bigramas y trigramas, elige los que no empiezan ni terminan con una stopword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos la clasificación de etiquetas PoS.\n",
    "\n",
    "<b>Etiquetas PoS</b>\n",
    "\n",
    "<ul>\n",
    "<li>DT: Determinante</li>\n",
    "<li>JJ: Adjetivo</li>\n",
    "<li>NN: Nombre en singular</li>\n",
    "<li>NNS: Nombre en plural</li>\n",
    "<li>VBD: Verbo en pasado</li>\n",
    "<li>VBG: Verbo en gerundio</li>\n",
    "<li>MD: Verbo modal</li>\n",
    "<li>IN: Preposición o conjunción subordinada</li>\n",
    "<li>PRP: Pronombre</li>\n",
    "<li>RB: Adverbio</li>\n",
    "<li>RP: Partícula</li>    \n",
    "<li>CC: Conjunción coordinada</li>\n",
    "<li>CD: Numeral</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "def get_coll_candidates(tokens):\n",
    "    bigramcandidates = BigramCollocationFinder.from_words(tokens)\n",
    "    trigramcandidates = TrigramCollocationFinder.from_words(tokens)\n",
    "    return bigramcandidates , trigramcandidates\n",
    "\n",
    "def get_n_best_candidates(bigram_candidates, trigram_candidates, n_best_collocations, metrica='pmi'):\n",
    "    if metrica == 'pmi':\n",
    "        nbest_bigram_candidates = bigram_candidates.nbest(bigram_measures.pmi,n_best_collocations)\n",
    "        nbest_trigram_candidates = trigram_candidates.nbest(trigram_measures.pmi,n_best_collocations)\n",
    "    \n",
    "    else:\n",
    "        nbest_bigram_candidates = bigram_candidates.nbest(bigram_measures.likelihood_ratio,n_best_collocations)\n",
    "        nbest_trigram_candidates = trigram_candidates.nbest(trigram_measures.likelihood_ratio,n_best_collocations)\n",
    "      \n",
    "    return nbest_bigram_candidates, nbest_trigram_candidates\n",
    "\n",
    "def good_stw_candidate(candidate):\n",
    "    test = True\n",
    "    if type(candidate) == str:\n",
    "        if candidate in stopwords:\n",
    "            test = False\n",
    "    else:\n",
    "        if len(candidate)==1:\n",
    "            if candidate[0] in stopwords:\n",
    "                test = False\n",
    "        else:\n",
    "            if len(candidate)==2:\n",
    "                if candidate[0][0] in stopwords or candidate[-1][0] in stopwords:\n",
    "                    test = False\n",
    "            else:\n",
    "                if candidate[0][0] in stopwords or candidate[1][0] in stopwords or candidate[-1][0] in stopwords:\n",
    "                    test = False\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n",
    "bigram_coll_candidates, trigram_coll_candidates = get_coll_candidates(tagged_tokens)\n",
    "\n",
    "nbest_bigram_candidates, nbest_trigram_candidates = get_n_best_candidates(bigram_coll_candidates, \n",
    "                                                                          trigram_coll_candidates, \n",
    "                                                                          1000)\n",
    "nbest_bigram_candidates_lr, nbest_trigram_candidates_lr = get_n_best_candidates(bigram_coll_candidates, \n",
    "                                                                          trigram_coll_candidates, \n",
    "                                                                          1000,\n",
    "                                                                          'lr')\n",
    "nbc_pmi=[] #bigramas con metrica pmi sin stopword\n",
    "nbc_lr=[]  #bigramas con metrica lr sin stopword\n",
    "ntc_pmi=[] #trigramas con metrica pmi sin stopword\n",
    "ntc_lr=[]  #trigramas con metrica lr sin stopword\n",
    "\n",
    "for i in range(0,1000):\n",
    "    if good_stw_candidate(nbest_bigram_candidates[i]):\n",
    "        nbc_pmi.append(nbest_bigram_candidates[i])\n",
    "    if good_stw_candidate(nbest_bigram_candidates_lr[i]):\n",
    "        nbc_lr.append(nbest_bigram_candidates_lr[i]) \n",
    "    if good_stw_candidate(nbest_trigram_candidates[i]):\n",
    "        ntc_pmi.append(nbest_trigram_candidates[i])\n",
    "    if good_stw_candidate(nbest_trigram_candidates_lr[i]):\n",
    "        ntc_lr.append(nbest_trigram_candidates_lr[i])  \n",
    "        \n",
    "        \n",
    "        \n",
    "print('Bigramas con métrica PMI  : ',len(nbc_pmi))\n",
    "print('Bigramas con métrica LR   : ',len(nbc_lr))\n",
    "print('Trigramas con métrica PMI : ',len(ntc_pmi))\n",
    "print('Trigramas con métrica LR  : ',len(ntc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong>  Escribe un comentario sobre los resultados obtenidos, contestando las siguientes preguntas: ¿Con las métricas utilizadas, es posible encontrar características distintivas en los ngramas de los titulares de noticias falsas? ¿Qué métrica te parece más adecuada para realizar este análisis? ¿Sería más eficiente detectar solamente ngramas que cumplen el patrón sintáctico de un sintagma nominal (e.g: adjetivo + nombre en singular/plural y nombre + nombre)? (1 punto)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vectorizar palabras y términos (3 puntos)\n",
    "\n",
    "Exploraremos la vectorización de palabras y términos con el método Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que el paquete gensim implementa un método para entrenar modelos Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong> Obtén los términos relacionados con 'coronavirus' en las noticias falsas y los términos relacionados con 'coronavirus' en las noticias verdaderas. Utiliza el cálculo de similitud semántica de un modelo word2vec (2 puntos)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer paso: Entrena un modelo de detección de phrases en una oración. Para el entrenamiento utiliza todos los titulares y los cuerpos (no vacíos) de las noticias falsas y verdaderas. Utiliza el módulo Phraser de Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import Phrases\n",
    "\n",
    "ss1 = [fh for fh in df_fake['title'].to_list() if fh != 'empty'] \n",
    "ss2 = [th for th in df_true['title'].to_list() if th != 'empty']\n",
    "ss3 = [ft for ft in df_fake['text'].to_list() if ft != 'empty']\n",
    "ss4 = [tt for tt in df_true['text'].to_list() if tt != 'empty']\n",
    "sentence_stream = ss1 + ss2 + ss3 + ss4 \n",
    "sentence_stream = \" \".join(sentence_stream).lower()\n",
    "\n",
    "text_stream = [w for w in word_tokenize(sentence_stream) if re.match(\"^[a-z]+.*\", w)]\n",
    "\n",
    "phrases = Phrases(text_stream, min_count=1, threshold=2)\n",
    "\n",
    "phraser = Phraser(phrases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo paso: Transforma cada frase de las noticias fake en una lista de phrases lematizadas\n",
    "\n",
    "<b>Atención</b>: Las phrases no deben ser stopwords. Tampoco deben empezar ni terminar con una stopword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "no_pos_in = ['DT', 'IN', 'PRP', 'CC', 'CD','MD', 'VBG', 'VBD', 'RP', 'RB']\n",
    "def get_wn_pos(pos):\n",
    "    if re.match(r'^N',pos):\n",
    "        wn_pos = 'n'\n",
    "    elif re.match(r'^V',pos):\n",
    "        wn_pos = 'v'\n",
    "    else:\n",
    "        wn_pos = 'n' #En inglés, los lemas de términos que no son verbos ni nombres se obtienen como si fueran\n",
    "                        #nombres\n",
    "    return wn_pos\n",
    "\n",
    "#La función wnlemmatize lematiza el término con una etiqueta PoS según el lematizador de Wordnet\n",
    "def wnlemmatize(t,postag):\n",
    "    lemma = \"\"\n",
    "    #Definición del lematizador\n",
    "    lem = WordNetLemmatizer()\n",
    "    #Si el candidato es monopalabra, se obtiene el lema con el lematizador de WordNet según su PoS\n",
    "    if ' ' not in t:\n",
    "        #lemma = lem.lemmatize(t,get_wn_pos(postag[0][1]))\n",
    "        lemma = lem.lemmatize(t,get_wn_pos(postag[1]))\n",
    "    #Si el candidato es multipalabra, obtenemos su lema como si fuera un nombre, aplicando el lematizador de WordNet\n",
    "    else:\n",
    "        lemma = lem.lemmatize(t,'n')\n",
    "    return lemma\n",
    "\n",
    "def transform_sentence(ss):\n",
    "    ss=ss.lower()\n",
    "    text_stream = [w for w in word_tokenize(ss) if re.match(\"^[a-z]+.*\", w) \n",
    "                                            and good_stw_candidate(w)\n",
    "                                            and nltk.pos_tag([w])[0][1] not in no_pos_in \n",
    "              ]\n",
    "    text_phrases=phraser[text_stream]\n",
    "\n",
    "    tagged_phrases = nltk.pos_tag(text_phrases)\n",
    "    lemmas=[]\n",
    "    for tm in range(0,len(text_phrases)):\n",
    "        lemmas.append(wnlemmatize(text_phrases[tm],tagged_phrases[tm]))\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "ss=ss1+ss3 #titulares y texto de las noticias falsas\n",
    "lemmas =  [transform_sentence(i) for i in ss]\n",
    "print(lemmas[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tercer paso: Crear un modelo word2vec de los titulares y los cuerpos de noticias falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2vnyt = Word2Vec( #gensim.models.Word2Vec(\n",
    "        lemmas\n",
    "        #size=150, # Tamaño de las dimensiones del vector\n",
    "        #window=10, #context window (10 palabras a la izquierda y 10 palabras a la derecha)\n",
    "        #min_count= 3, #Frecuencia mínima\n",
    "        #workers= 1,\n",
    "        #seed=1 # Valor de inicio predefinido para conservar la coherencia\n",
    ")\n",
    "#... y lo entrenamos con los documentos transformados\n",
    "w2vnyt.train(lemmas, total_examples=len(lemmas), epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuarto paso: Seleccionar el vocabulario del modelo word2vec sobre el cual se verán los términos parecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "phrases_vocabulary = list(w2vnyt.wv.key_to_index.keys())\n",
    "#print(phrases_vocabulary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quinto paso: Presentar los términos fake más cercanos semánticamente a 'coronavirus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "term = 'coronavirus'\n",
    "\n",
    "#Considerando los términos como feature names, la relación feature name-distancia se expresa en forma de tupla. \n",
    "#El primer elemento de la tupla es el feature name y el segundo elemento es su valor de distancia a un término\n",
    "#de referencia (e.g. Trump) según #Word2Vec. Estas tuplas se van poniendo en una lista (w2v_tuples) para que luego \n",
    "#puedan ser ordenadas de más cercanas a menos cercanas\n",
    "\n",
    "w2v_tuples = []\n",
    "\n",
    "feature_names = phrases_vocabulary\n",
    "\n",
    "#Para cada feature name, calculamos su distancia respecto al término de referencia con el método model.similarity.\n",
    "#Si la distancia es superior a 0, la tupla se pone en la lista de tuplas\n",
    "for i in range(0, len(feature_names)):\n",
    "    if feature_names[i] != term and w2vnyt.wv.similarity(term, feature_names[i]) > 0:\n",
    "        w2v_tuples.append((feature_names[i], w2vnyt.wv.similarity(term, feature_names[i])))\n",
    "    \n",
    "#Se ordenan las tuplas\n",
    "w2v_sorted_tuples = sorted(w2v_tuples, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "#print(w2v_sorted_tuples)\n",
    "\n",
    "labels = ['Term', 'Distance']\n",
    "\n",
    "#Se crea dataframe a partir del cual se construirá la tabla\n",
    "df4 = pd.DataFrame.from_records(w2v_sorted_tuples, columns=labels)\n",
    "\n",
    "#Construcción y visualización de la tabla\n",
    "print (\"\")\n",
    "print (\"Distancia respecto al término\", term) \n",
    "print (\"\")\n",
    "\n",
    "print (df4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sexto paso: Realiza los pasos anteriores pero con las frases de las noticias verdaderas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "ss_true=ss2+ss4 #titulares y texto de las noticias verdaderas\n",
    "lemmas_true =  [transform_sentence(i) for i in ss_true]\n",
    "w2vnyt_true = Word2Vec(lemmas_true)\n",
    "w2vnyt_true.train(lemmas_true, total_examples=len(lemmas_true), epochs=10)\n",
    "phrases_vocabulary_true = list(w2vnyt_true.wv.key_to_index.keys())\n",
    "w2v_tuples_true = []\n",
    "\n",
    "feature_names = phrases_vocabulary_true\n",
    "\n",
    "for i in range(0, len(feature_names)):\n",
    "    if feature_names[i] != term and w2vnyt_true.wv.similarity(term, feature_names[i]) > 0:\n",
    "        w2v_tuples_true.append((feature_names[i], w2vnyt_true.wv.similarity(term, feature_names[i])))\n",
    "    \n",
    "w2v_sorted_tuples_true = sorted(w2v_tuples_true, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "labels = ['Term', 'Distance']\n",
    "\n",
    "df4 = pd.DataFrame.from_records(w2v_sorted_tuples_true, columns=labels)\n",
    "\n",
    "print (\"\")\n",
    "print (\"Distancia respecto al término\", term) \n",
    "print (\"\")\n",
    "\n",
    "print (df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong> Comenta las diferencias que existen en los términos relacionados con 'coronavirus' en las noticias falsas y en las noticias verdaderas. ¿Crees que estas diferencias son representativas de los contenidos de las noticias falsas? (1 punto)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detección de temas. (4 puntos)\n",
    "\n",
    "En estos apartados exploraremos los temas tratados en las noticias falsas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploración de los temas con WordNet (2 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado accederemos a Wordnet a través de la librería nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong> Comprueba si las noticias falsas contienen términos alejados semánticamente del sentido del término 'disease' en Wordnet. Compruébalo calculando la similitud de Wu and Palmer entre el sentido de wordnet 'disease.n.01' y los términos relacionados con 'coronavirus' en el modelo word2vec de las noticias falsas. (1 punto)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer paso: Calcula la distancia Wu and Palmer entre el sentido 'disease.n.01' y el primer sentido de los sustantivos más relacionados con 'coronavirus' en el modelo word2vec de las noticias falsas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "disease = wn.synset('disease.n.01')\n",
    "novel = wn.synset('novel.n.01')\n",
    "strain = wn.synset('strain.n.01')\n",
    "outbreak = wn.synset('outbreak.n.01')\n",
    "coincidence = wn.synset('coincidence.n.01')\n",
    "#coronavirus.however = wn.synset('coronavirus.n.01')\n",
    "remedy = wn.synset('remedy.n.01')\n",
    "\n",
    "#united_states = wn.synset('united_states.n.01')\n",
    "#spain = wn.synset('spain.n.01')\n",
    "\n",
    "print(\"LA DISTANCIA SEMÁNTICA ENTRE 'disease' Y 'novel' ES \", disease.wup_similarity(novel)) #Wu and Palmer score\n",
    "print(\"LA DISTANCIA SEMÁNTICA ENTRE 'disease' Y 'strain' ES \", disease.wup_similarity(strain))\n",
    "print(\"LA DISTANCIA SEMÁNTICA ENTRE 'disease' Y 'outbreak' ES \", disease.wup_similarity(outbreak))\n",
    "print(\"LA DISTANCIA SEMÁNTICA ENTRE 'disease' Y 'coincidence' ES \", disease.wup_similarity(coincidence))\n",
    "#print(\"LA DISTANCIA SEMÁNTICA ENTRE 'disease' Y 'coronavirus' ES \", disease.wup_similarity(coronavirus))\n",
    "print(\"LA DISTANCIA SEMÁNTICA ENTRE 'disease' Y 'remedy' ES \", disease.wup_similarity(remedy))\n",
    "                   \n",
    "#print(\"LA DISTANCIA SEMÁNTICA ENTRE 'UNITED STATES' Y 'SPAIN' ES \", united_states.wup_similarity(spain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong> Comenta los resultados que te han llamado más la atención. Fíjate en los términos que no están en Wordnet y los que tienen una distancia muy alejada al sentido de disease.n.01. ¿Crees que Wordnet es un buen recurso para analizar los temas que se tratan en las noticias falsas sobre el coronavirus? (1 punto)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LDA (2 puntos)\n",
    "\n",
    "Recordemos que en el notebook del módulo 1 hemos visto la aplicación del método LDA para extraer temas de documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong> Extrae temas a partir de los phrases de los titulares y los cuerpos de noticias falsas. Lo haremos con el método LDA. Experimenta con el parámetro num_topics hasta encontrar un conjunto de temas informativo, y asigna nombres a los temas encontrados. La construcción del modelo LDA puede tardar más de 10 minutos en algunos casos (2 puntos)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "def isnp(t):\n",
    "    v = False\n",
    "    #Si el término es una multipalabra, asumimos que es un término nominal\n",
    "    if ' ' in t:\n",
    "        v = True\n",
    "    #Si el término monopalabra no tiene synset en Wordnet, asumimos que es un término nominal que todavía no se ha \n",
    "    #incluido en Wordnet\n",
    "    elif wn.synsets(t) == []: \n",
    "        v = True\n",
    "    else:\n",
    "        try:\n",
    "            #Si existe un synset del término que es nominal, entonces el término es nominal \n",
    "            wn.synset(t + '.n.01')\n",
    "            v = True\n",
    "        except:\n",
    "            pass\n",
    "    return v    \n",
    "\n",
    "\n",
    "def get_nominals(sentence):\n",
    "    #Términos nominales con una frecuencia mínima de 3 (son los términos del modelo Word2Vec)\n",
    "    nps = [np for np in sentence if np in terms_vocabulary \n",
    "           and isnp(np) == True ] \n",
    "    return nps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Método para hacer el LDA\n",
    "\n",
    "def lda(terms):\n",
    "    dictionary = corpora.Dictionary(terms)\n",
    "    #print(dictionary)\n",
    "    # Creación del corpus\n",
    "    texts = terms\n",
    "    # Frecuencia de los términos en cada documento. El formato está en forma de tupla,\n",
    "    #(índice del término en el diccionario/vocabulario, frecuencia). Por ejemplo, [(0, 2), (1, 1), (2, 1), (3, 1)])\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    #Creación del modelo.\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, # Frecuencia de los términos en cada documento\n",
    "                                               num_topics=7, #Número de temas\n",
    "                                               random_state=1, #Valor de inicio predefinido para conservar \n",
    "                                                               #coherencia\n",
    "                                               id2word = dictionary, #El vocabulario\n",
    "                                               passes=500) # Cuantos más pases, más consistente el modelo\n",
    "\n",
    "    return ldamodel\n",
    "\n",
    "nps_in_sentences = [get_nominals(ts) for ts in transformed_sentences if len(get_nominals(ts)) > 0]\n",
    "\n",
    "ldamodel = lda(nps_in_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clasificación (1 punto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong> Crea un clasificador automático de noticias falsas y no falsas a partir de los titulares. (0.5 puntos)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer paso: Unimos el dataframe con las noticias falsas y el dataframe con las noticias verdaderas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo paso: Realizamos dos listas. Una con los titulares y otra con las etiquetas correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tercer paso: Vectorizamos los titulares con un vectorizador tf.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuarto paso:Preparamos el corpus de entrenamiento y de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quinto paso: Entrenar el clasificador con Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sexto paso: Utilizar el modelo entrenado para predecir la categoría Fake o True de los titulares del conjunto de test y mostrar las palabras más informativas para cada categoría. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio:</strong> A partir de las palabras más informativas, ¿qué contenidos crees que son típicos de las noticias falsas sobre el coronavirus? ¿Crees que hay que considerar elementos formales (e.g: ausencia de titular, uso de mayúsculas) como distintivos de las noticias falsas? (0.5 puntos)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
